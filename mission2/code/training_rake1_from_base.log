INFO 2025-12-07 01:29:34 ot_train.py:163 {'batch_size': 8,
 'checkpoint_path': None,
 'dataset': {'episodes': None,
             'image_transforms': {'enable': False,
                                  'max_num_transforms': 3,
                                  'random_order': False,
                                  'tfs': {'affine': {'kwargs': {'degrees': [-5.0,
                                                                            5.0],
                                                                'translate': [0.05,
                                                                              0.05]},
                                                     'type': 'RandomAffine',
                                                     'weight': 1.0},
                                          'brightness': {'kwargs': {'brightness': [0.8,
                                                                                   1.2]},
                                                         'type': 'ColorJitter',
                                                         'weight': 1.0},
                                          'contrast': {'kwargs': {'contrast': [0.8,
                                                                               1.2]},
                                                       'type': 'ColorJitter',
                                                       'weight': 1.0},
                                          'hue': {'kwargs': {'hue': [-0.05,
                                                                     0.05]},
                                                  'type': 'ColorJitter',
                                                  'weight': 1.0},
                                          'saturation': {'kwargs': {'saturation': [0.5,
                                                                                   1.5]},
                                                         'type': 'ColorJitter',
                                                         'weight': 1.0},
                                          'sharpness': {'kwargs': {'sharpness': [0.5,
                                                                                 1.5]},
                                                        'type': 'SharpnessJitter',
                                                        'weight': 1.0}}},
             'repo_id': 'wmeddie/zenbot_rake1',
             'revision': None,
             'root': None,
             'streaming': False,
             'use_imagenet_stats': True,
             'video_backend': 'pyav'},
 'env': None,
 'eval': {'batch_size': 50, 'n_episodes': 50, 'use_async_envs': False},
 'eval_freq': 20000,
 'job_name': 'smolvla',
 'log_freq': 200,
 'num_workers': 8,
 'optimizer': {'betas': [0.9, 0.95],
               'eps': 1e-08,
               'grad_clip_norm': 10.0,
               'lr': 0.0001,
               'type': 'adamw',
               'weight_decay': 1e-10},
 'output_dir': 'outputs/smolvla_rake1_from_base',
 'policy': {'adapt_to_pi_aloha': False,
            'add_image_special_tokens': False,
            'attention_mode': 'cross_attn',
            'chunk_size': 50,
            'device': 'cuda',
            'empty_cameras': 1,
            'expert_width_multiplier': 0.75,
            'freeze_vision_encoder': True,
            'input_features': {'observation.images.camera1': {'shape': [3,
                                                                        256,
                                                                        256],
                                                              'type': <FeatureType.VISUAL: 'VISUAL'>},
                               'observation.images.camera2': {'shape': [3,
                                                                        256,
                                                                        256],
                                                              'type': <FeatureType.VISUAL: 'VISUAL'>},
                               'observation.images.camera3': {'shape': [3,
                                                                        256,
                                                                        256],
                                                              'type': <FeatureType.VISUAL: 'VISUAL'>},
                               'observation.state': {'shape': [6],
                                                     'type': <FeatureType.STATE: 'STATE'>}},
            'license': None,
            'load_vlm_weights': True,
            'max_action_dim': 32,
            'max_period': 4.0,
            'max_state_dim': 32,
            'min_period': 0.004,
            'n_action_steps': 50,
            'n_obs_steps': 1,
            'normalization_mapping': {'ACTION': <NormalizationMode.MEAN_STD: 'MEAN_STD'>,
                                      'STATE': <NormalizationMode.MEAN_STD: 'MEAN_STD'>,
                                      'VISUAL': <NormalizationMode.IDENTITY: 'IDENTITY'>},
            'num_expert_layers': 0,
            'num_steps': 10,
            'num_vlm_layers': 16,
            'optimizer_betas': [0.9, 0.95],
            'optimizer_eps': 1e-08,
            'optimizer_grad_clip_norm': 10.0,
            'optimizer_lr': 0.0001,
            'optimizer_weight_decay': 1e-10,
            'output_features': {'action': {'shape': [6],
                                           'type': <FeatureType.ACTION: 'ACTION'>}},
            'pad_language_to': 'max_length',
            'prefix_length': 0,
            'pretrained_path': 'lerobot/smolvla_base',
            'private': None,
            'push_to_hub': True,
            'repo_id': 'wmeddie/smolvla_rake1',
            'resize_imgs_with_padding': [512, 512],
            'scheduler_decay_lr': 2.5e-06,
            'scheduler_decay_steps': 30000,
            'scheduler_warmup_steps': 1000,
            'self_attn_every_n_layers': 2,
            'tags': None,
            'tokenizer_max_length': 48,
            'train_expert_only': True,
            'train_state_proj': True,
            'type': 'smolvla',
            'use_amp': False,
            'use_cache': True,
            'use_delta_joint_actions_aloha': False,
            'vlm_model_name': 'HuggingFaceTB/SmolVLM2-500M-Video-Instruct'},
 'rename_map': {'observation.images.front': 'observation.images.camera1',
                'observation.images.top': 'observation.images.camera2'},
 'resume': False,
 'save_checkpoint': True,
 'save_freq': 5000,
 'scheduler': {'decay_lr': 2.5e-06,
               'num_decay_steps': 30000,
               'num_warmup_steps': 1000,
               'peak_lr': 0.0001,
               'type': 'cosine_decay_with_warmup'},
 'seed': 1000,
 'steps': 20000,
 'use_policy_training_preset': True,
 'wandb': {'disable_artifact': False,
           'enable': True,
           'entity': 'wm_eddie',
           'mode': None,
           'notes': None,
           'project': 'zenbot',
           'run_id': None}}
/opt/venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
INFO 2025-12-07 01:29:35 db_utils.py:102 Logs will be synced with wandb.
INFO 2025-12-07 01:29:35 db_utils.py:103 Track this run --> https://wandb.ai/wm_eddie/zenbot/runs/m1cbwyoh
INFO 2025-12-07 01:29:35 ot_train.py:183 Creating dataset
INFO 2025-12-07 01:29:35 ot_train.py:202 Creating policy
`torch_dtype` is deprecated! Use `dtype` instead!
INFO 2025-12-07 01:29:45 ot_train.py:247 Creating optimizer and scheduler
INFO 2025-12-07 01:29:45 hedulers.py:105 Auto-scaling LR scheduler: num_training_steps (20000) < num_decay_steps (30000). Scaling warmup: 1000 → 666, decay: 30000 → 20000 (scale factor: 0.667)
INFO 2025-12-07 01:29:45 ot_train.py:259 Output dir: outputs/smolvla_rake1_from_base
INFO 2025-12-07 01:29:45 ot_train.py:262 cfg.steps=20000 (20K)
INFO 2025-12-07 01:29:45 ot_train.py:263 dataset.num_frames=23914 (24K)
INFO 2025-12-07 01:29:45 ot_train.py:264 dataset.num_episodes=10
INFO 2025-12-07 01:29:45 ot_train.py:267 Effective batch size: 8 x 1 = 8
INFO 2025-12-07 01:29:45 ot_train.py:268 num_learnable_params=99880992 (100M)
INFO 2025-12-07 01:29:45 ot_train.py:269 num_total_params=450046176 (450M)
INFO 2025-12-07 01:29:45 ot_train.py:324 Start offline training on a fixed dataset
Loading  HuggingFaceTB/SmolVLM2-500M-Video-Instruct weights ...
Reducing the number of VLM layers to 16 ...
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
INFO 2025-12-07 01:30:39 ot_train.py:351 step:200 smpl:2K ep:1 epch:0.07 loss:0.068 grdn:1.229 lr:1.5e-05 updt_s:0.257 data_s:0.013
WARNING 2025-12-07 01:30:39 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:30:39 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:31:08 ot_train.py:351 step:400 smpl:3K ep:1 epch:0.13 loss:0.058 grdn:1.216 lr:4.5e-05 updt_s:0.137 data_s:0.004
WARNING 2025-12-07 01:31:08 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:31:08 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:31:36 ot_train.py:351 step:600 smpl:5K ep:2 epch:0.20 loss:0.059 grdn:1.115 lr:7.5e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 01:31:36 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:31:36 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:32:04 ot_train.py:351 step:800 smpl:6K ep:3 epch:0.27 loss:0.071 grdn:1.233 lr:9.8e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 01:32:04 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:32:04 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:32:32 ot_train.py:351 step:1K smpl:8K ep:3 epch:0.33 loss:0.066 grdn:1.083 lr:1.0e-04 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 01:32:32 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:32:32 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:33:00 ot_train.py:351 step:1K smpl:10K ep:4 epch:0.40 loss:0.061 grdn:0.941 lr:9.9e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 01:33:00 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:33:00 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:33:29 ot_train.py:351 step:1K smpl:11K ep:5 epch:0.47 loss:0.055 grdn:0.877 lr:9.9e-05 updt_s:0.137 data_s:0.004
WARNING 2025-12-07 01:33:29 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:33:29 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:33:57 ot_train.py:351 step:2K smpl:13K ep:5 epch:0.54 loss:0.055 grdn:0.846 lr:9.9e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 01:33:57 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:33:57 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:34:25 ot_train.py:351 step:2K smpl:14K ep:6 epch:0.60 loss:0.053 grdn:0.841 lr:9.8e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 01:34:25 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:34:25 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:34:53 ot_train.py:351 step:2K smpl:16K ep:7 epch:0.67 loss:0.051 grdn:0.799 lr:9.8e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 01:34:53 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:34:53 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:35:21 ot_train.py:351 step:2K smpl:18K ep:7 epch:0.74 loss:0.048 grdn:0.777 lr:9.7e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 01:35:21 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:35:21 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:35:50 ot_train.py:351 step:2K smpl:19K ep:8 epch:0.80 loss:0.046 grdn:0.718 lr:9.7e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 01:35:50 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:35:50 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:36:18 ot_train.py:351 step:3K smpl:21K ep:9 epch:0.87 loss:0.045 grdn:0.731 lr:9.6e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 01:36:18 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:36:18 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:36:46 ot_train.py:351 step:3K smpl:22K ep:9 epch:0.94 loss:0.046 grdn:0.723 lr:9.6e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 01:36:46 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:36:46 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
INFO 2025-12-07 01:37:18 ot_train.py:351 step:3K smpl:24K ep:10 epch:1.00 loss:0.046 grdn:0.760 lr:9.5e-05 updt_s:0.134 data_s:0.028
WARNING 2025-12-07 01:37:18 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:37:18 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:37:46 ot_train.py:351 step:3K smpl:26K ep:11 epch:1.07 loss:0.041 grdn:0.684 lr:9.4e-05 updt_s:0.133 data_s:0.004
WARNING 2025-12-07 01:37:46 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:37:46 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:38:14 ot_train.py:351 step:3K smpl:27K ep:11 epch:1.14 loss:0.038 grdn:0.650 lr:9.4e-05 updt_s:0.134 data_s:0.004
WARNING 2025-12-07 01:38:14 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:38:14 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:38:42 ot_train.py:351 step:4K smpl:29K ep:12 epch:1.20 loss:0.038 grdn:0.633 lr:9.3e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 01:38:42 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:38:42 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:39:10 ot_train.py:351 step:4K smpl:30K ep:13 epch:1.27 loss:0.037 grdn:0.621 lr:9.2e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 01:39:10 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:39:10 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:39:39 ot_train.py:351 step:4K smpl:32K ep:13 epch:1.34 loss:0.035 grdn:0.629 lr:9.1e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 01:39:39 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:39:39 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:40:07 ot_train.py:351 step:4K smpl:34K ep:14 epch:1.41 loss:0.034 grdn:0.614 lr:9.0e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 01:40:07 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:40:07 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:40:35 ot_train.py:351 step:4K smpl:35K ep:15 epch:1.47 loss:0.034 grdn:0.602 lr:8.9e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 01:40:35 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:40:35 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:41:04 ot_train.py:351 step:5K smpl:37K ep:15 epch:1.54 loss:0.035 grdn:0.595 lr:8.8e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 01:41:04 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:41:04 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:41:32 ot_train.py:351 step:5K smpl:38K ep:16 epch:1.61 loss:0.032 grdn:0.567 lr:8.7e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 01:41:32 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:41:32 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:42:00 ot_train.py:351 step:5K smpl:40K ep:17 epch:1.67 loss:0.032 grdn:0.573 lr:8.6e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 01:42:00 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:42:00 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:42:00 ot_train.py:361 Checkpoint policy after step 5000
INFO 2025-12-07 01:42:32 ot_train.py:351 step:5K smpl:42K ep:17 epch:1.74 loss:0.031 grdn:0.560 lr:8.5e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 01:42:32 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:42:32 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:43:00 ot_train.py:351 step:5K smpl:43K ep:18 epch:1.81 loss:0.031 grdn:0.537 lr:8.4e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 01:43:00 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:43:00 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:43:28 ot_train.py:351 step:6K smpl:45K ep:19 epch:1.87 loss:0.028 grdn:0.510 lr:8.3e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 01:43:28 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:43:28 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:43:56 ot_train.py:351 step:6K smpl:46K ep:19 epch:1.94 loss:0.029 grdn:0.525 lr:8.2e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 01:43:56 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:43:56 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
INFO 2025-12-07 01:44:29 ot_train.py:351 step:6K smpl:48K ep:20 epch:2.01 loss:0.027 grdn:0.512 lr:8.1e-05 updt_s:0.134 data_s:0.030
WARNING 2025-12-07 01:44:29 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:44:29 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:44:58 ot_train.py:351 step:6K smpl:50K ep:21 epch:2.07 loss:0.026 grdn:0.482 lr:7.9e-05 updt_s:0.138 data_s:0.004
WARNING 2025-12-07 01:44:58 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:44:58 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:45:26 ot_train.py:351 step:6K smpl:51K ep:21 epch:2.14 loss:0.026 grdn:0.494 lr:7.8e-05 updt_s:0.138 data_s:0.004
WARNING 2025-12-07 01:45:26 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:45:26 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:45:55 ot_train.py:351 step:7K smpl:53K ep:22 epch:2.21 loss:0.027 grdn:0.506 lr:7.7e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 01:45:55 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:45:55 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:46:23 ot_train.py:351 step:7K smpl:54K ep:23 epch:2.27 loss:0.026 grdn:0.469 lr:7.5e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 01:46:23 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:46:23 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:46:51 ot_train.py:351 step:7K smpl:56K ep:23 epch:2.34 loss:0.024 grdn:0.456 lr:7.4e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 01:46:51 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:46:51 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:47:20 ot_train.py:351 step:7K smpl:58K ep:24 epch:2.41 loss:0.025 grdn:0.481 lr:7.3e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 01:47:20 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:47:20 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:47:48 ot_train.py:351 step:7K smpl:59K ep:25 epch:2.48 loss:0.025 grdn:0.459 lr:7.1e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 01:47:48 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:47:48 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:48:16 ot_train.py:351 step:8K smpl:61K ep:25 epch:2.54 loss:0.023 grdn:0.451 lr:7.0e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 01:48:16 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:48:16 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:48:44 ot_train.py:351 step:8K smpl:62K ep:26 epch:2.61 loss:0.022 grdn:0.430 lr:6.8e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 01:48:44 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:48:44 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:49:12 ot_train.py:351 step:8K smpl:64K ep:27 epch:2.68 loss:0.021 grdn:0.421 lr:6.7e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 01:49:12 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:49:12 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:49:40 ot_train.py:351 step:8K smpl:66K ep:27 epch:2.74 loss:0.023 grdn:0.427 lr:6.6e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 01:49:40 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:49:40 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:50:08 ot_train.py:351 step:8K smpl:67K ep:28 epch:2.81 loss:0.021 grdn:0.415 lr:6.4e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 01:50:08 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:50:08 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:50:36 ot_train.py:351 step:9K smpl:69K ep:29 epch:2.88 loss:0.021 grdn:0.407 lr:6.3e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 01:50:36 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:50:36 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:51:05 ot_train.py:351 step:9K smpl:70K ep:29 epch:2.94 loss:0.020 grdn:0.401 lr:6.1e-05 updt_s:0.139 data_s:0.004
WARNING 2025-12-07 01:51:05 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:51:05 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
INFO 2025-12-07 01:51:38 ot_train.py:351 step:9K smpl:72K ep:30 epch:3.01 loss:0.020 grdn:0.404 lr:6.0e-05 updt_s:0.133 data_s:0.029
WARNING 2025-12-07 01:51:38 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:51:38 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:52:06 ot_train.py:351 step:9K smpl:74K ep:31 epch:3.08 loss:0.018 grdn:0.373 lr:5.8e-05 updt_s:0.137 data_s:0.004
WARNING 2025-12-07 01:52:06 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:52:06 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:52:35 ot_train.py:351 step:9K smpl:75K ep:31 epch:3.14 loss:0.018 grdn:0.385 lr:5.7e-05 updt_s:0.139 data_s:0.005
WARNING 2025-12-07 01:52:35 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:52:35 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:53:03 ot_train.py:351 step:10K smpl:77K ep:32 epch:3.21 loss:0.018 grdn:0.375 lr:5.5e-05 updt_s:0.134 data_s:0.004
WARNING 2025-12-07 01:53:03 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:53:03 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:53:31 ot_train.py:351 step:10K smpl:78K ep:33 epch:3.28 loss:0.018 grdn:0.386 lr:5.4e-05 updt_s:0.134 data_s:0.004
WARNING 2025-12-07 01:53:31 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:53:31 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:53:59 ot_train.py:351 step:10K smpl:80K ep:33 epch:3.35 loss:0.018 grdn:0.367 lr:5.2e-05 updt_s:0.134 data_s:0.004
WARNING 2025-12-07 01:53:59 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:53:59 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:53:59 ot_train.py:361 Checkpoint policy after step 10000
INFO 2025-12-07 01:54:31 ot_train.py:351 step:10K smpl:82K ep:34 epch:3.41 loss:0.017 grdn:0.347 lr:5.0e-05 updt_s:0.134 data_s:0.004
WARNING 2025-12-07 01:54:31 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:54:31 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:54:58 ot_train.py:351 step:10K smpl:83K ep:35 epch:3.48 loss:0.017 grdn:0.342 lr:4.9e-05 updt_s:0.134 data_s:0.004
WARNING 2025-12-07 01:54:58 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:54:58 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:55:26 ot_train.py:351 step:11K smpl:85K ep:35 epch:3.55 loss:0.017 grdn:0.359 lr:4.7e-05 updt_s:0.134 data_s:0.004
WARNING 2025-12-07 01:55:26 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:55:26 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:55:54 ot_train.py:351 step:11K smpl:86K ep:36 epch:3.61 loss:0.016 grdn:0.339 lr:4.6e-05 updt_s:0.134 data_s:0.004
WARNING 2025-12-07 01:55:54 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:55:54 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:56:22 ot_train.py:351 step:11K smpl:88K ep:37 epch:3.68 loss:0.016 grdn:0.337 lr:4.4e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 01:56:22 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:56:22 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:56:50 ot_train.py:351 step:11K smpl:90K ep:37 epch:3.75 loss:0.017 grdn:0.345 lr:4.3e-05 updt_s:0.134 data_s:0.004
WARNING 2025-12-07 01:56:50 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:56:50 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:57:18 ot_train.py:351 step:11K smpl:91K ep:38 epch:3.81 loss:0.016 grdn:0.327 lr:4.1e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 01:57:18 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:57:18 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:57:46 ot_train.py:351 step:12K smpl:93K ep:39 epch:3.88 loss:0.016 grdn:0.331 lr:4.0e-05 updt_s:0.133 data_s:0.004
WARNING 2025-12-07 01:57:46 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:57:46 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:58:14 ot_train.py:351 step:12K smpl:94K ep:39 epch:3.95 loss:0.015 grdn:0.328 lr:3.8e-05 updt_s:0.134 data_s:0.004
WARNING 2025-12-07 01:58:14 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:58:14 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
INFO 2025-12-07 01:58:48 ot_train.py:351 step:12K smpl:96K ep:40 epch:4.01 loss:0.016 grdn:0.322 lr:3.7e-05 updt_s:0.134 data_s:0.033
WARNING 2025-12-07 01:58:48 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:58:48 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:59:17 ot_train.py:351 step:12K smpl:98K ep:41 epch:4.08 loss:0.014 grdn:0.304 lr:3.5e-05 updt_s:0.141 data_s:0.004
WARNING 2025-12-07 01:59:17 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:59:17 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 01:59:46 ot_train.py:351 step:12K smpl:99K ep:41 epch:4.15 loss:0.014 grdn:0.296 lr:3.4e-05 updt_s:0.140 data_s:0.004
WARNING 2025-12-07 01:59:46 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 01:59:46 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:00:15 ot_train.py:351 step:13K smpl:101K ep:42 epch:4.22 loss:0.014 grdn:0.305 lr:3.3e-05 updt_s:0.139 data_s:0.004
WARNING 2025-12-07 02:00:15 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:00:15 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:00:44 ot_train.py:351 step:13K smpl:102K ep:43 epch:4.28 loss:0.014 grdn:0.304 lr:3.1e-05 updt_s:0.138 data_s:0.004
WARNING 2025-12-07 02:00:44 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:00:44 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:01:12 ot_train.py:351 step:13K smpl:104K ep:43 epch:4.35 loss:0.014 grdn:0.288 lr:3.0e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 02:01:12 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:01:12 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:01:40 ot_train.py:351 step:13K smpl:106K ep:44 epch:4.42 loss:0.013 grdn:0.285 lr:2.8e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 02:01:40 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:01:40 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:02:09 ot_train.py:351 step:13K smpl:107K ep:45 epch:4.48 loss:0.013 grdn:0.278 lr:2.7e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 02:02:09 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:02:09 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:02:37 ot_train.py:351 step:14K smpl:109K ep:45 epch:4.55 loss:0.013 grdn:0.281 lr:2.6e-05 updt_s:0.137 data_s:0.004
WARNING 2025-12-07 02:02:37 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:02:37 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:03:05 ot_train.py:351 step:14K smpl:110K ep:46 epch:4.62 loss:0.012 grdn:0.270 lr:2.4e-05 updt_s:0.137 data_s:0.004
WARNING 2025-12-07 02:03:05 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:03:05 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:03:34 ot_train.py:351 step:14K smpl:112K ep:47 epch:4.68 loss:0.013 grdn:0.278 lr:2.3e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 02:03:34 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:03:34 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:04:02 ot_train.py:351 step:14K smpl:114K ep:48 epch:4.75 loss:0.013 grdn:0.270 lr:2.2e-05 updt_s:0.137 data_s:0.004
WARNING 2025-12-07 02:04:02 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:04:02 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:04:31 ot_train.py:351 step:14K smpl:115K ep:48 epch:4.82 loss:0.013 grdn:0.275 lr:2.1e-05 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 02:04:31 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:04:31 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:04:59 ot_train.py:351 step:15K smpl:117K ep:49 epch:4.88 loss:0.011 grdn:0.240 lr:2.0e-05 updt_s:0.138 data_s:0.004
WARNING 2025-12-07 02:04:59 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:04:59 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:05:28 ot_train.py:351 step:15K smpl:118K ep:50 epch:4.95 loss:0.012 grdn:0.256 lr:1.8e-05 updt_s:0.138 data_s:0.004
WARNING 2025-12-07 02:05:28 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:05:28 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
INFO 2025-12-07 02:06:01 ot_train.py:351 step:15K smpl:120K ep:50 epch:5.02 loss:0.012 grdn:0.269 lr:1.7e-05 updt_s:0.135 data_s:0.031
WARNING 2025-12-07 02:06:01 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:06:01 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:06:01 ot_train.py:361 Checkpoint policy after step 15000
INFO 2025-12-07 02:06:33 ot_train.py:351 step:15K smpl:122K ep:51 epch:5.08 loss:0.012 grdn:0.246 lr:1.6e-05 updt_s:0.134 data_s:0.004
WARNING 2025-12-07 02:06:33 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:06:33 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:07:01 ot_train.py:351 step:15K smpl:123K ep:52 epch:5.15 loss:0.012 grdn:0.247 lr:1.5e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 02:07:01 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:07:01 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:07:29 ot_train.py:351 step:16K smpl:125K ep:52 epch:5.22 loss:0.012 grdn:0.253 lr:1.4e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 02:07:29 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:07:29 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:07:57 ot_train.py:351 step:16K smpl:126K ep:53 epch:5.29 loss:0.012 grdn:0.250 lr:1.3e-05 updt_s:0.134 data_s:0.004
WARNING 2025-12-07 02:07:57 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:07:57 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:08:25 ot_train.py:351 step:16K smpl:128K ep:54 epch:5.35 loss:0.011 grdn:0.240 lr:1.2e-05 updt_s:0.134 data_s:0.004
WARNING 2025-12-07 02:08:25 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:08:25 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:08:53 ot_train.py:351 step:16K smpl:130K ep:54 epch:5.42 loss:0.011 grdn:0.240 lr:1.1e-05 updt_s:0.134 data_s:0.004
WARNING 2025-12-07 02:08:53 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:08:53 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:09:21 ot_train.py:351 step:16K smpl:131K ep:55 epch:5.49 loss:0.011 grdn:0.243 lr:1.1e-05 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 02:09:21 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:09:21 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:09:49 ot_train.py:351 step:17K smpl:133K ep:56 epch:5.55 loss:0.011 grdn:0.241 lr:9.7e-06 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 02:09:49 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:09:49 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:10:17 ot_train.py:351 step:17K smpl:134K ep:56 epch:5.62 loss:0.012 grdn:0.245 lr:8.9e-06 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 02:10:17 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:10:17 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:10:45 ot_train.py:351 step:17K smpl:136K ep:57 epch:5.69 loss:0.011 grdn:0.229 lr:8.2e-06 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 02:10:45 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:10:45 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:11:13 ot_train.py:351 step:17K smpl:138K ep:58 epch:5.75 loss:0.012 grdn:0.237 lr:7.5e-06 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 02:11:13 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:11:13 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:11:41 ot_train.py:351 step:17K smpl:139K ep:58 epch:5.82 loss:0.011 grdn:0.232 lr:6.8e-06 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 02:11:41 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:11:41 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:12:09 ot_train.py:351 step:18K smpl:141K ep:59 epch:5.89 loss:0.011 grdn:0.235 lr:6.2e-06 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 02:12:09 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:12:09 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:12:37 ot_train.py:351 step:18K smpl:142K ep:60 epch:5.95 loss:0.010 grdn:0.226 lr:5.6e-06 updt_s:0.135 data_s:0.004
WARNING 2025-12-07 02:12:37 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:12:37 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
/opt/venv/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec
  warnings.warn(
INFO 2025-12-07 02:13:10 ot_train.py:351 step:18K smpl:144K ep:60 epch:6.02 loss:0.011 grdn:0.229 lr:5.1e-06 updt_s:0.134 data_s:0.033
WARNING 2025-12-07 02:13:10 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:13:10 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:13:40 ot_train.py:351 step:18K smpl:146K ep:61 epch:6.09 loss:0.011 grdn:0.224 lr:4.7e-06 updt_s:0.140 data_s:0.005
WARNING 2025-12-07 02:13:40 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:13:40 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:14:09 ot_train.py:351 step:18K smpl:147K ep:62 epch:6.16 loss:0.012 grdn:0.237 lr:4.2e-06 updt_s:0.139 data_s:0.005
WARNING 2025-12-07 02:14:09 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:14:09 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:14:38 ot_train.py:351 step:19K smpl:149K ep:62 epch:6.22 loss:0.011 grdn:0.226 lr:3.8e-06 updt_s:0.139 data_s:0.005
WARNING 2025-12-07 02:14:38 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:14:38 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:15:07 ot_train.py:351 step:19K smpl:150K ep:63 epch:6.29 loss:0.010 grdn:0.215 lr:3.5e-06 updt_s:0.140 data_s:0.004
WARNING 2025-12-07 02:15:07 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:15:07 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:15:36 ot_train.py:351 step:19K smpl:152K ep:64 epch:6.36 loss:0.011 grdn:0.219 lr:3.2e-06 updt_s:0.140 data_s:0.005
WARNING 2025-12-07 02:15:36 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:15:36 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:16:05 ot_train.py:351 step:19K smpl:154K ep:64 epch:6.42 loss:0.010 grdn:0.218 lr:3.0e-06 updt_s:0.140 data_s:0.004
WARNING 2025-12-07 02:16:05 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:16:05 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:16:34 ot_train.py:351 step:19K smpl:155K ep:65 epch:6.49 loss:0.011 grdn:0.223 lr:2.8e-06 updt_s:0.138 data_s:0.004
WARNING 2025-12-07 02:16:34 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:16:34 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:17:03 ot_train.py:351 step:20K smpl:157K ep:66 epch:6.56 loss:0.011 grdn:0.226 lr:2.7e-06 updt_s:0.139 data_s:0.004
WARNING 2025-12-07 02:17:03 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:17:03 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:17:31 ot_train.py:351 step:20K smpl:158K ep:66 epch:6.62 loss:0.011 grdn:0.228 lr:2.6e-06 updt_s:0.136 data_s:0.004
WARNING 2025-12-07 02:17:31 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:17:31 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:18:00 ot_train.py:351 step:20K smpl:160K ep:67 epch:6.69 loss:0.011 grdn:0.224 lr:2.5e-06 updt_s:0.137 data_s:0.004
WARNING 2025-12-07 02:18:00 db_utils.py:141 WandB logging of key "losses_after_forward" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
WARNING 2025-12-07 02:18:00 db_utils.py:141 WandB logging of key "losses_after_rm_padding" was ignored as its type "<class 'torch.Tensor'>" is not handled by this wrapper.
INFO 2025-12-07 02:18:00 ot_train.py:361 Checkpoint policy after step 20000
INFO 2025-12-07 02:18:04 ot_train.py:430 End of training
Traceback (most recent call last):
  File "/opt/venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py", line 407, in hf_raise_for_status
    response.raise_for_status()
  File "/opt/venv/lib/python3.12/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/api/models/wmeddie/smolvla_rake1/xet-write-token/main

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/venv/bin/lerobot-train", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/opt/venv/lib/python3.12/site-packages/lerobot/scripts/lerobot_train.py", line 444, in main
    train()
  File "/opt/venv/lib/python3.12/site-packages/lerobot/configs/parser.py", line 233, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.12/site-packages/lerobot/scripts/lerobot_train.py", line 434, in train
    unwrapped_policy.push_model_to_hub(cfg)
  File "/opt/venv/lib/python3.12/site-packages/lerobot/policies/pretrained.py", line 228, in push_model_to_hub
    commit_info = api.upload_folder(
                  ^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py", line 1669, in _inner
    return fn(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py", line 4993, in upload_folder
    commit_info = self.create_commit(
                  ^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py", line 1669, in _inner
    return fn(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py", line 4250, in create_commit
    self.preupload_lfs_files(
  File "/opt/venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py", line 4534, in preupload_lfs_files
    _upload_xet_files(**upload_kwargs, create_pr=create_pr)  # type: ignore [arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.12/site-packages/huggingface_hub/_commit_api.py", line 538, in _upload_xet_files
    xet_connection_info = fetch_xet_connection_info_from_repo_info(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.12/site-packages/huggingface_hub/utils/_xet.py", line 158, in fetch_xet_connection_info_from_repo_info
    return _fetch_xet_connection_info_with_url(url, headers, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.12/site-packages/huggingface_hub/utils/_xet.py", line 187, in _fetch_xet_connection_info_with_url
    hf_raise_for_status(resp)
  File "/opt/venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py", line 471, in hf_raise_for_status
    raise _format(HfHubHTTPError, message, response) from e
huggingface_hub.errors.HfHubHTTPError: (Request ID: Root=1-6934e3de-1c062114547a787c3e5cd1f3;ac5ded67-a1d8-437e-9554-fde8b24018e9)

403 Forbidden: Forbidden: pass `create_pr=1` as a query parameter to create a Pull Request.
Cannot access content at: https://huggingface.co/api/models/wmeddie/smolvla_rake1/xet-write-token/main.
Make sure your token has the correct permissions.
